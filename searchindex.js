Search.setIndex({"alltitles": {"Action": [[56, null], [63, "action"]], "Action in deep learning.": [[56, "action-in-deep-learning"]], "Activation Functions": [[22, null]], "Actor Critic": [[55, null]], "Add data.": [[48, "add-data"]], "Adversarial-based methods.": [[68, "adversarial-based-methods"]], "Agent": [[57, null], [63, "agent"]], "Agent in deep learning.": [[57, "agent-in-deep-learning"]], "Agent, is that you?": [[57, "agent-is-that-you"]], "Approximation models": [[0, null]], "Are VAEs better?": [[17, "are-vaes-better"]], "Are policies the same thing as agents?": [[61, "are-policies-the-same-thing-as-agents"]], "Areas to improve": [[8, "areas-to-improve"]], "Attention": [[39, null]], "Attention is all you need": [[45, "attention-is-all-you-need"]], "Auto Encoder Architecture": [[15, null]], "Auto Regression": [[71, null]], "AutoEncoder Model": [[14, null]], "Batch size": [[47, null], [53, "batch-size"]], "Batch size too big": [[47, "batch-size-too-big"]], "Batch size too small": [[47, "batch-size-too-small"]], "Before we start": [[21, "before-we-start"]], "Besides what we\u2019ve seen so far.": [[53, "besides-what-we-ve-seen-so-far"]], "Calculate gradients for Linear Layers": [[32, null]], "Can different learning rates be used on different parameters at the same time?": [[52, "can-different-learning-rates-be-used-on-different-parameters-at-the-same-time"]], "Can we share latent between different decoders (maybe of different architecture)?": [[15, "can-we-share-latent-between-different-decoders-maybe-of-different-architecture"]], "Chain rule": [[3, "chain-rule"]], "Classification": [[70, null], [73, "classification"]], "Clustering": [[74, null], [78, "clustering"]], "Clustering clustering methods": [[74, "clustering-clustering-methods"]], "Convolution Layer": [[27, null]], "DBSCAN": [[74, "dbscan"]], "Data": [[1, "data"], [2, null]], "Decision Tree": [[75, null]], "Decision tree": [[78, "decision-tree"]], "Definition": [[23, "definition"], [24, "definition"], [25, "definition"]], "Difference with Life Long Learning.": [[13, "difference-with-life-long-learning"]], "Different techniques in TL/DA.": [[68, "different-techniques-in-tl-da"]], "Discrepancy-based methods.": [[68, "discrepancy-based-methods"]], "Do actions speak louder than words?": [[56, "do-actions-speak-louder-than-words"]], "Do loss functions have to be differentiable?": [[5, null]], "Domain adaptation definition.": [[69, "domain-adaptation-definition"]], "Don\u2019t change the model too much.": [[12, "don-t-change-the-model-too-much"]], "Don\u2019t learn new things that conflict with what the model already knows.": [[12, "don-t-learn-new-things-that-conflict-with-what-the-model-already-knows"]], "Don\u2019t use certain activation functions": [[50, "don-t-use-certain-activation-functions"]], "Dropout Layer": [[28, null]], "Embedding Layer": [[29, null]], "Example of loss functions that don\u2019t need to be differentiable to be useful?": [[5, "example-of-loss-functions-that-don-t-need-to-be-differentiable-to-be-useful"]], "Example usage of chain rule": [[3, "example-usage-of-chain-rule"]], "Explainable AI": [[8, "explainable-ai"], [10, null]], "GANs in algorithm.": [[18, "gans-in-algorithm"]], "GMM": [[74, "gmm"]], "Gated Linear Unit": [[36, null]], "Gaussian Mixture Model": [[20, null]], "Generative Adversarial Models": [[18, null]], "Generative Models": [[19, null]], "Gradient Vanishing / Gradient Explosion": [[50, null]], "Gradient descent.": [[4, "gradient-descent"]], "Gradient issues": [[53, "gradient-issues"]], "Gradients": [[4, null]], "Hierarchy methods": [[74, "hierarchy-methods"]], "Holy Trinity for Machine Learning": [[1, null]], "How Gradients Are Calculated?": [[3, null]], "How LLL works?": [[12, "how-lll-works"]], "How are Q functions better?": [[64, "how-are-q-functions-better"]], "How autoencoders do this?": [[14, "how-autoencoders-do-this"]], "How do GANs work?": [[18, "how-do-gans-work"]], "How do decision trees work?": [[75, "how-do-decision-trees-work"]], "How do generative models generate things?": [[19, "how-do-generative-models-generate-things"]], "How does GMM look?": [[20, "how-does-gmm-look"]], "How does ReLU look, and how it works in code?": [[23, "how-does-relu-look-and-how-it-works-in-code"]], "How does a linear layer work?": [[31, "how-does-a-linear-layer-work"]], "How does classification work?": [[70, "how-does-classification-work"]], "How does regression work?": [[72, "how-does-regression-work"]], "How does sigmoid look, and how it works in code?": [[24, "how-does-sigmoid-look-and-how-it-works-in-code"]], "How does softmax look, and how it works in code?": [[25, "how-does-softmax-look-and-how-it-works-in-code"]], "How does tanh look, and how it works in code?": [[26, "how-does-tanh-look-and-how-it-works-in-code"]], "How does the transformer work?": [[45, "how-does-the-transformer-work"]], "How hard can training be?": [[53, "how-hard-can-training-be"]], "How is TL different from DA?": [[69, "how-is-tl-different-from-da"]], "How is semi-supervised training different from unsupervised training?": [[77, "how-is-semi-supervised-training-different-from-unsupervised-training"]], "How should I choose my LR?": [[52, "how-should-i-choose-my-lr"]], "How to deal with gradient vanishing or explosion?": [[50, "how-to-deal-with-gradient-vanishing-or-explosion"]], "How to deal with overfitting?": [[48, "how-to-deal-with-overfitting"]], "How to deal with underfitting?": [[49, "how-to-deal-with-underfitting"]], "How to determine if a function is differentiable?": [[4, "how-to-determine-if-a-function-is-differentiable"]], "How to make a decision?": [[75, "how-to-make-a-decision"]], "How to meta learning?": [[13, "how-to-meta-learning"]], "How to take an AE and say: this part is the encoder, and this part is the decoder?": [[15, "how-to-take-an-ae-and-say-this-part-is-the-encoder-and-this-part-is-the-decoder"]], "How to use this book?": [[21, "how-to-use-this-book"]], "How well can a model approximate?": [[0, "how-well-can-a-model-approximate"]], "Hyperbolic Tangent": [[26, null]], "I want to do machine learning. How?": [[1, "i-want-to-do-machine-learning-how"]], "Important terms in RL.": [[63, "important-terms-in-rl"]], "Improvements to a model": [[8, null]], "Improving Auto Encoders with Semi Supervised Training": [[16, null]], "In simple terms.": [[69, "in-simple-terms"]], "Increase model size.": [[49, "increase-model-size"]], "Introduction": [[21, null], [23, "introduction"], [24, "introduction"], [25, "introduction"], [26, "introduction"]], "Is it possible that the model only remembers the last batch it sees?": [[47, "is-it-possible-that-the-model-only-remembers-the-last-batch-it-sees"]], "Just explain it": [[10, "just-explain-it"]], "K-means": [[74, "k-means"]], "Knowledge Distillation": [[66, null]], "Layers": [[30, null]], "Layers in code": [[30, "layers-in-code"]], "Learning Rate": [[52, null]], "Learning rate": [[53, "learning-rate"]], "Life Long Learning": [[12, null]], "Life long learning": [[8, "life-long-learning"]], "Linear Layer": [[31, null]], "Linear layers in code?": [[31, "linear-layers-in-code"]], "Long Short Term Memory": [[37, null]], "Loss": [[1, "loss"]], "Loss Function": [[6, null]], "Main approaches for explainable AI systems": [[10, "main-approaches-for-explainable-ai-systems"]], "Make the model bigger.": [[12, "make-the-model-bigger"]], "Markov Decision Process": [[63, "markov-decision-process"]], "Meta Learning": [[13, null]], "Meta learning": [[8, "meta-learning"]], "Mix-in data in old tasks when learning new tasks.": [[12, "mix-in-data-in-old-tasks-when-learning-new-tasks"]], "Model": [[1, "model"], [7, null]], "Model Compression": [[9, null]], "Model compression": [[8, "model-compression"]], "Most common unsupervised methods": [[78, "most-common-unsupervised-methods"]], "Normal mode": [[42, "normal-mode"]], "Normalization": [[50, "normalization"]], "Normalization Layer": [[33, null]], "Offline methods.": [[58, "offline-methods"]], "Online Methods vs Offline Methods": [[58, null]], "Online methods.": [[58, "online-methods"]], "Optimizer": [[53, "optimizer"], [54, null]], "Other Things To Notice": [[53, null]], "Overfit": [[48, null]], "Overfitting and underfitting": [[53, "overfitting-and-underfitting"]], "Padding Layer": [[34, null]], "Policy": [[61, null], [63, "policy"]], "Policy Gradient": [[62, null]], "Policy in RL.": [[61, "policy-in-rl"]], "Pooling Layer": [[35, null]], "Positional encoding": [[45, "positional-encoding"]], "Proximal Policy Optimization.": [[55, "proximal-policy-optimization"]], "Q Learning": [[64, null]], "Q learning in simple terms.": [[64, "q-learning-in-simple-terms"]], "Quantization": [[9, "quantization"]], "Reconstruction-based methods.": [[68, "reconstruction-based-methods"]], "Rectified Linear Unit": [[23, null]], "Recurrent Layer": [[38, null]], "Reduce model size.": [[48, "reduce-model-size"]], "Reduce some data.": [[49, "reduce-some-data"]], "Reduce the hyper-parameters of the model.": [[48, "reduce-the-hyper-parameters-of-the-model"]], "Regression": [[72, null], [73, "regression"]], "Regularization.": [[48, "regularization"]], "Reinforce?": [[63, "reinforce"]], "Reinforcement Learning": [[63, null]], "Relation between value function and rewards.": [[65, "relation-between-value-function-and-rewards"]], "Removing a part, and see what gets affected": [[10, "removing-a-part-and-see-what-gets-affected"]], "Residual Networks": [[50, "residual-networks"]], "Reusing Existing Models": [[67, null]], "Reward": [[59, null], [63, "reward"]], "Rewards are for?": [[59, "rewards-are-for"]], "Rewards in deep learning.": [[59, "rewards-in-deep-learning"]], "Saddle point": [[51, null]], "Saliency Maps": [[11, null]], "Scheduled sampling": [[42, "scheduled-sampling"]], "See what parts of the input yield the biggest gradients": [[10, "see-what-parts-of-the-input-yield-the-biggest-gradients"]], "Self Attention": [[40, null]], "Self Supervised Learning": [[76, null]], "Self supervised": [[78, "self-supervised"]], "Self supervised learning vs unsupervised learning?": [[76, "self-supervised-learning-vs-unsupervised-learning"]], "Semi Supervised Training": [[77, null]], "Semi supervised": [[78, "semi-supervised"]], "Should I design my AE\u2019s decoder to be symmetry to its encoder?": [[15, "should-i-design-my-ae-s-decoder-to-be-symmetry-to-its-encoder"]], "Sigmoid": [[24, null]], "So how does PyTorch calculate gradients?": [[3, "so-how-does-pytorch-calculate-gradients"]], "So, how should I choose batch sizes?": [[47, "so-how-should-i-choose-batch-sizes"]], "Softmax": [[25, null]], "State": [[60, null], [63, "state"]], "State in deep learning.": [[60, "state-in-deep-learning"]], "Structured pruning": [[9, "structured-pruning"]], "Summary": [[9, "summary"], [53, "summary"]], "Teacher Forcing vs Scheduled Sampling vs Normal Mode": [[42, null]], "Teacher forcing": [[42, "teacher-forcing"]], "The need for loss functions": [[6, "the-need-for-loss-functions"]], "The need of model compression": [[9, "the-need-of-model-compression"]], "The policy gradient in simple terms.": [[62, "the-policy-gradient-in-simple-terms"]], "The training does not converge.": [[47, "the-training-does-not-converge"]], "The training flow of KD.": [[66, "the-training-flow-of-kd"]], "Token": [[43, null]], "Training Transformers": [[44, null]], "Training takes a long time.": [[47, "training-takes-a-long-time"]], "Training takes a lot of time.": [[47, "training-takes-a-lot-of-time"]], "Transfer Learning and Domain Adaptation": [[68, null]], "Transfer Learning vs Domain Adaptation": [[69, null]], "Transfer learning definition.": [[69, "transfer-learning-definition"]], "Transformer Block": [[45, null]], "Transformer decoder": [[45, "transformer-decoder"]], "Transformer encoder": [[45, "transformer-encoder"]], "Transformer vs RNN": [[46, null]], "Try attention in code": [[39, "try-attention-in-code"]], "Types of tasks": [[73, null]], "Underfit": [[49, null]], "Unstructured pruning": [[9, "unstructured-pruning"]], "Unsupervised Learning": [[78, null]], "Unsupervised learning?": [[78, "id1"]], "Using Bert without training?": [[41, null]], "Using semi-supervised to aid AE\u2019s performance": [[16, "using-semi-supervised-to-aid-ae-s-performance"]], "Value": [[63, "value"], [65, null]], "Value function in RL": [[65, "value-function-in-rl"]], "Variational AutoEncoder Model": [[17, null]], "Ways of doing model compression": [[9, "ways-of-doing-model-compression"]], "What are GMMs?": [[20, "what-are-gmms"]], "What are GRUs?": [[36, "what-are-grus"]], "What are LR?": [[52, "what-are-lr"]], "What are LSTMs?": [[37, "what-are-lstms"]], "What are activation functions?": [[22, "what-are-activation-functions"]], "What are batches": [[47, "what-are-batches"]], "What are clustering methods?": [[74, "what-are-clustering-methods"]], "What are data?": [[2, "what-are-data"]], "What are layers?": [[30, "what-are-layers"]], "What are optimizers?": [[54, "what-are-optimizers"]], "What are pooling layers?": [[35, "what-are-pooling-layers"]], "What are saliency maps?": [[11, "what-are-saliency-maps"]], "What are some common layers?": [[30, "what-are-some-common-layers"]], "What do GANs do?": [[18, "what-do-gans-do"]], "What do Norm layers do?": [[33, "what-do-norm-layers-do"]], "What do convolution layers do?": [[27, "what-do-convolution-layers-do"]], "What do embedding layers do?": [[29, "what-do-embedding-layers-do"]], "What do linear layers do?": [[31, "what-do-linear-layers-do"]], "What do padding layers do?": [[34, "what-do-padding-layers-do"]], "What do recurrent layers do?": [[38, "what-do-recurrent-layers-do"]], "What do you mean by variational?": [[17, "what-do-you-mean-by-variational"]], "What does auto-regression mean?": [[71, "what-does-auto-regression-mean"]], "What does dropout layers do?": [[28, "what-does-dropout-layers-do"]], "What does underfit mean?": [[49, "what-does-underfit-mean"]], "What exactly is a loss function?": [[6, "what-exactly-is-a-loss-function"]], "What happens when a model overfit?": [[48, "what-happens-when-a-model-overfit"]], "What happens when gradients vanish or explode?": [[50, "what-happens-when-gradients-vanish-or-explode"]], "What is KD, and do we need it?": [[66, "what-is-kd-and-do-we-need-it"]], "What is RL?": [[63, "what-is-rl"]], "What is a Q function?": [[64, "what-is-a-q-function"]], "What is a model?": [[7, "what-is-a-model"]], "What is a saddle point?": [[51, "what-is-a-saddle-point"]], "What is actor critic?": [[55, "what-is-actor-critic"]], "What is an approximation model?": [[0, "what-is-an-approximation-model"]], "What is this book?": [[21, "what-is-this-book"]], "What state are you in?": [[60, "what-state-are-you-in"]], "What\u2019s attention?": [[39, "what-s-attention"]], "What\u2019s meta learning?": [[13, "what-s-meta-learning"]], "When do gradients vanish or explode?": [[50, "when-do-gradients-vanish-or-explode"]], "When do saddle points appear?": [[51, "when-do-saddle-points-appear"]], "When do we need TL/DA?": [[68, "when-do-we-need-tl-da"]], "When does overfitting happen?": [[48, "when-does-overfitting-happen"]], "When to use GMMs?": [[20, "when-to-use-gmms"]], "When to use GRUs?": [[36, "when-to-use-grus"]], "When to use LSTMs?": [[37, "when-to-use-lstms"]], "When to use Norm layers?": [[33, "when-to-use-norm-layers"]], "When to use a convolution layer?": [[27, "when-to-use-a-convolution-layer"]], "When to use dropout layers?": [[28, "when-to-use-dropout-layers"]], "When to use embedding layers?": [[29, "when-to-use-embedding-layers"]], "When to use linear layers?": [[31, "when-to-use-linear-layers"]], "When to use padding layers?": [[34, "when-to-use-padding-layers"]], "When to use pooling layers?": [[35, "when-to-use-pooling-layers"]], "When to use recurrent layers?": [[38, "when-to-use-recurrent-layers"]], "Where can policy gradients be applied?": [[62, "where-can-policy-gradients-be-applied"]], "Why GMMs use Gaussians?": [[20, "why-gmms-use-gaussians"]], "Why LLL?": [[12, "why-lll"]], "Why activations?": [[22, "why-activations"]], "Why are RNNs good?": [[46, "why-are-rnns-good"]], "Why are RNNs not good enough?": [[46, "why-are-rnns-not-good-enough"]], "Why are autoencoders generative models?": [[14, "why-are-autoencoders-generative-models"]], "Why are gradients useful?": [[4, "why-are-gradients-useful"]], "Why are transformers all the rage?": [[46, "why-are-transformers-all-the-rage"]], "Why attention?": [[39, "why-attention"]], "Why autoencoders?": [[14, "why-autoencoders"]], "Why classification?": [[70, "why-classification"]], "Why deeper is better?": [[0, "why-deeper-is-better"]], "Why do we need data?": [[2, "why-do-we-need-data"]], "Why do we need models?": [[7, "why-do-we-need-models"]], "Why don\u2019t we train a model from scratch?": [[66, "why-don-t-we-train-a-model-from-scratch"]], "Why generative models?": [[19, "why-generative-models"]], "Why learn machine learning?": [[21, "why-learn-machine-learning"]], "Why not to worry about saddle points?": [[51, "why-not-to-worry-about-saddle-points"]], "Why regression?": [[72, "why-regression"]], "Why this Book?": [[21, "why-this-book"]], "Why value functions are important?": [[65, "why-value-functions-are-important"]], "Why?": [[10, "why"]]}, "docnames": ["basics/approx/approx", "basics/basics", "basics/data/data", "basics/gradients/back-prop", "basics/gradients/gradients", "basics/gradients/loss-fn-derivative", "basics/loss/loss", "basics/model/model", "better/better", "better/compression/compression", "better/explainable/explainable", "better/explainable/saliency", "better/lll/lll", "better/meta/meta", "generative/ae/ae", "generative/ae/ae-arch", "generative/ae/ae-semi", "generative/ae/vae/vae", "generative/gan/gan", "generative/generative", "generative/gmm/gmm", "intro", "layers/activation/activation", "layers/activation/relu/relu", "layers/activation/sigmoid/sigmoid", "layers/activation/softmax/softmax", "layers/activation/tanh/tanh", "layers/cnn/cnn", "layers/dropout/dropout", "layers/emb/emb", "layers/layers", "layers/linear/linear", "layers/linear/linear-grad", "layers/norm/norm", "layers/padding/padding", "layers/pooling/pooling", "layers/rnn/gru/gru", "layers/rnn/lstm/lstm", "layers/rnn/rnn", "layers/transformer/attn/attn", "layers/transformer/attn/self-attn", "layers/transformer/training/no-training/no-training", "layers/transformer/training/teacher/teacher", "layers/transformer/training/token/token", "layers/transformer/training/training", "layers/transformer/transformer", "layers/transformer/transformer-vs-rnn", "notice/batch/batch", "notice/data/overfit", "notice/data/underfit", "notice/gradient/norm", "notice/gradient/saddle", "notice/lr/lr", "notice/notice", "notice/optimizer/optimizer", "reinforce/ac/ac", "reinforce/essential/action", "reinforce/essential/agent", "reinforce/essential/online-offline", "reinforce/essential/reward", "reinforce/essential/state", "reinforce/policy/policy", "reinforce/policy/policy-gradient", "reinforce/reinforce", "reinforce/value/q-learning", "reinforce/value/value", "reuse/distil/distil", "reuse/reuse", "reuse/transfer/tl-da", "reuse/transfer/tl-vs-da", "tasks/classification/classification", "tasks/regression/auto/auto", "tasks/regression/regression", "tasks/tasks", "unsupervised/clustering/clustering", "unsupervised/decision-tree/decision-tree", "unsupervised/self-supervised/self-supervised", "unsupervised/semi-supervised/semi-supervised", "unsupervised/unsupervised"], "envversion": {"sphinx": 62, "sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1}, "filenames": ["basics/approx/approx.ipynb", "basics/basics.ipynb", "basics/data/data.ipynb", "basics/gradients/back-prop.ipynb", "basics/gradients/gradients.ipynb", "basics/gradients/loss-fn-derivative.ipynb", "basics/loss/loss.ipynb", "basics/model/model.ipynb", "better/better.ipynb", "better/compression/compression.ipynb", "better/explainable/explainable.ipynb", "better/explainable/saliency.ipynb", "better/lll/lll.ipynb", "better/meta/meta.ipynb", "generative/ae/ae.ipynb", "generative/ae/ae-arch.ipynb", "generative/ae/ae-semi.ipynb", "generative/ae/vae/vae.ipynb", "generative/gan/gan.ipynb", "generative/generative.ipynb", "generative/gmm/gmm.ipynb", "intro.ipynb", "layers/activation/activation.ipynb", "layers/activation/relu/relu.ipynb", "layers/activation/sigmoid/sigmoid.ipynb", "layers/activation/softmax/softmax.ipynb", "layers/activation/tanh/tanh.ipynb", "layers/cnn/cnn.ipynb", "layers/dropout/dropout.ipynb", "layers/emb/emb.ipynb", "layers/layers.ipynb", "layers/linear/linear.ipynb", "layers/linear/linear-grad.ipynb", "layers/norm/norm.ipynb", "layers/padding/padding.ipynb", "layers/pooling/pooling.ipynb", "layers/rnn/gru/gru.ipynb", "layers/rnn/lstm/lstm.ipynb", "layers/rnn/rnn.ipynb", "layers/transformer/attn/attn.ipynb", "layers/transformer/attn/self-attn.ipynb", "layers/transformer/training/no-training/no-training.ipynb", "layers/transformer/training/teacher/teacher.ipynb", "layers/transformer/training/token/token.ipynb", "layers/transformer/training/training.ipynb", "layers/transformer/transformer.ipynb", "layers/transformer/transformer-vs-rnn.ipynb", "notice/batch/batch.ipynb", "notice/data/overfit.ipynb", "notice/data/underfit.ipynb", "notice/gradient/norm.ipynb", "notice/gradient/saddle.ipynb", "notice/lr/lr.ipynb", "notice/notice.ipynb", "notice/optimizer/optimizer.ipynb", "reinforce/ac/ac.ipynb", "reinforce/essential/action.ipynb", "reinforce/essential/agent.ipynb", "reinforce/essential/online-offline.ipynb", "reinforce/essential/reward.ipynb", "reinforce/essential/state.ipynb", "reinforce/policy/policy.ipynb", "reinforce/policy/policy-gradient.ipynb", "reinforce/reinforce.ipynb", "reinforce/value/q-learning.ipynb", "reinforce/value/value.ipynb", "reuse/distil/distil.ipynb", "reuse/reuse.ipynb", "reuse/transfer/tl-da.ipynb", "reuse/transfer/tl-vs-da.ipynb", "tasks/classification/classification.ipynb", "tasks/regression/auto/auto.ipynb", "tasks/regression/regression.ipynb", "tasks/tasks.ipynb", "unsupervised/clustering/clustering.ipynb", "unsupervised/decision-tree/decision-tree.ipynb", "unsupervised/self-supervised/self-supervised.ipynb", "unsupervised/semi-supervised/semi-supervised.ipynb", "unsupervised/unsupervised.ipynb"], "indexentries": {}, "objects": {}, "objnames": {}, "objtypes": {}, "terms": {"": [0, 1, 3, 4, 7, 8, 9, 10, 12, 14, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 30, 31, 35, 36, 38, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 60, 61, 62, 63, 64, 65, 66, 68, 70, 71, 72, 74, 75], "0": [0, 18, 20, 22, 23, 24, 25, 26, 30, 31, 34, 39, 43, 47, 50, 64, 65, 72], "00000000e": 24, "00883903": 25, "01": [24, 39], "0162": 30, "02": [24, 39], "02249394": 25, "0266": 31, "0280": 31, "03": [24, 39], "0306": 30, "03292528": 25, "04": 24, "0477": 30, "05": 24, "05h": 72, "07": 39, "072473": 25, "0747": 31, "08175574e": 39, "0911": 31, "0987": 31, "1": [0, 18, 20, 22, 23, 24, 25, 26, 27, 31, 39, 42, 43, 47, 64, 65, 68], "10": [23, 24, 26, 47, 50], "100": [23, 47, 65], "10000": 0, "11": [23, 24, 26], "110": [23, 65], "11051194e": 24, "12": 0, "125": 3, "16": 9, "16306542": 25, "1799": 31, "1912": 30, "19202922e": 24, "19790164": 25, "2": [0, 3, 20, 23, 24, 25, 26, 27, 31, 35, 39, 42, 43, 47, 64, 68, 70], "20": [20, 24, 25, 26], "200": [20, 24, 25, 26], "201": 20, "2021": 70, "210": [24, 25, 26], "2259": 31, "23394576e": 24, "2487": 31, "2593": 30, "2671": 30, "2d": 0, "3": [0, 3, 23, 24, 26, 30, 31, 39, 42, 45, 47], "300": 50, "3000": 72, "3014": 31, "31058579e": 24, "3139": 31, "3144": 31, "32": [9, 47], "3463": 31, "35350130e": 24, "3636403": 39, "36638669e": 39, "375": 3, "37874797": 39, "3840": 31, "3904505311192348": 39, "4": [0, 23, 24, 26, 30, 31], "410": 25, "41402607833904426": 39, "4165": 31, "4244410525601183": 25, "42573952": 39, "425739522152238": 39, "4422": 31, "4472": 31, "4547": 30, "47262316e": 24, "4774": 31, "478602216244276": 25, "47860282": 25, "478602824865396": 25, "48788493e": 39, "5": [3, 23, 24, 25, 26, 30, 39, 65], "50": 65, "5187": 30, "52293566": 39, "52574127e": 24, "53978687e": 24, "5734": 31, "5770": 31, "5801": 30, "59": 72, "59107159": 25, "6": [20, 23, 24, 26, 30], "60": 72, "60000": 0, "61992632e": 39, "64": 9, "6752": 31, "68941421e": 24, "69248268e": 39, "69285092e": 24, "7": [23, 24, 26], "70904236": 25, "74258732e": 24, "76159416": 26, "79862100e": 24, "8": [0, 3, 23, 24, 26], "80797078e": 24, "82013790e": 24, "85": 41, "86384348": 39, "894956874308216": 25, "9": [23, 24, 26, 39], "93307149e": 24, "96402758": 26, "97206664": 25, "97527377e": 24, "99": 51, "99088949e": 24, "99505475": 26, "99664650e": 24, "99876605e": 24, "999": 51, "9993293": 26, "99954602e": 24, "9999092": 26, "99998771": 26, "99999834": 26, "99999977": 26, "99999997": 26, "A": [0, 2, 3, 6, 7, 12, 18, 19, 20, 22, 23, 27, 30, 31, 35, 36, 37, 38, 43, 45, 47, 51, 54, 60, 63, 64, 65, 68, 70, 74, 75], "And": [8, 20, 21, 22, 30, 39, 46, 63, 65, 68], "As": 9, "At": 43, "Being": [10, 46], "But": [15, 30, 35, 53, 60, 68, 70], "By": [12, 68], "For": [0, 3, 4, 9, 11, 13, 14, 17, 19, 29, 31, 35, 39, 45, 46, 47, 48, 50, 57, 60, 61, 65, 68, 69, 72], "If": [0, 3, 5, 9, 10, 11, 12, 14, 15, 22, 31, 33, 42, 43, 47, 50, 52, 53, 56, 57, 63, 64, 70, 72, 74, 75], "In": [0, 2, 4, 6, 8, 9, 10, 11, 12, 13, 14, 17, 19, 21, 22, 39, 41, 43, 45, 47, 48, 50, 52, 56, 58, 60, 61, 63, 64, 70, 72, 73, 76], "It": [0, 3, 4, 7, 8, 9, 10, 11, 14, 15, 16, 18, 19, 20, 21, 22, 26, 28, 30, 31, 36, 39, 41, 42, 43, 45, 47, 49, 53, 55, 56, 59, 66, 70, 71], "Its": [36, 37, 74], "Not": [36, 39], "Of": 9, "On": 59, "One": [0, 16, 39], "Or": [2, 10, 13, 43, 48, 53, 70], "Such": 18, "That": [4, 12, 13, 14, 20, 22, 45, 46, 47, 50, 51, 60, 75], "The": [0, 1, 2, 3, 4, 7, 14, 16, 18, 20, 21, 34, 36, 42, 43, 45, 46, 50, 52, 55, 59, 64, 68, 70, 74], "Then": [3, 64, 65], "There": [2, 4, 9, 12, 15, 16, 18, 21, 27, 31, 34, 42, 47, 50, 53, 70, 72], "These": [7, 9, 22, 74], "To": [11, 13, 22, 25, 51, 62], "With": [0, 3, 20, 25, 51, 52], "__init__": 30, "_i": 62, "ab": 20, "abbrevi": [18, 36, 37, 52, 66, 68, 74], "abid": 22, "abil": [12, 19], "abl": [3, 10, 12, 14, 19, 45, 75], "about": [0, 1, 2, 4, 7, 8, 12, 13, 14, 21, 22, 35, 41, 45, 55, 60, 63, 69], "abov": [10, 18, 42, 70], "accompani": 21, "accord": [55, 61], "accordingli": 61, "accur": [0, 9, 42, 64], "achiev": [11, 30, 41, 45, 52], "acquir": 8, "across": 68, "act": [35, 55, 61, 74], "action": [7, 57, 59, 61, 62, 64, 65, 73], "activ": [0, 23, 45], "actual": [6, 45, 47], "ad": [17, 22, 31, 45, 48, 55], "adagrad": 52, "adam": 52, "adapt": 13, "add": [41, 45], "addbackward0": 31, "addit": 60, "advantag": 55, "ae": [17, 19], "affect": [12, 45, 51], "after": [7, 9, 12, 14, 22, 45, 50, 56, 58, 64, 65], "ag": 65, "again": [38, 47, 72], "against": 4, "agent": [55, 56, 59, 64, 65], "aggreg": 27, "aggress": 17, "agre": 63, "ai": [21, 41], "aim": [11, 21, 65, 68, 69], "algebra": [9, 31], "algorithm": [5, 10, 11, 13, 52, 55, 57, 64, 69, 74], "alic": 45, "align": 68, "all": [0, 6, 7, 14, 15, 18, 20, 21, 22, 23, 30, 31, 34, 38, 39, 49, 51, 53, 55, 57, 64, 65, 66, 68, 70, 72, 73, 74, 78], "allow": [22, 36, 37, 57], "almost": [18, 33, 34, 37], "along": [4, 10, 14, 45, 65], "alphago": 10, "alreadi": [15, 64], "also": [3, 9, 12, 14, 20, 26, 27, 31, 35, 45, 46, 47, 51, 52, 56, 60, 63, 68], "altern": 34, "although": 55, "alwai": [4, 33, 34, 37, 42, 52, 56], "amount": [9, 10, 12, 14], "an": [5, 9, 10, 11, 14, 19, 21, 22, 27, 29, 30, 34, 35, 38, 45, 47, 48, 49, 52, 53, 55, 56, 57, 60, 61, 63, 64, 65, 68, 69, 70, 71, 72], "ani": [0, 8, 12, 14, 20, 22, 45, 57], "anim": [63, 73], "anoth": [16, 22, 27, 31, 43, 47, 64, 66, 68, 69, 73, 74], "answer": [2, 3, 15], "anymor": 0, "anyth": [2, 9, 21, 30, 38, 53, 56, 57, 63, 70], "anywai": 22, "apart": 68, "appeal": 41, "appear": [45, 48], "append": 71, "appl": 29, "appli": [12, 22, 25, 45, 50, 55, 57, 68, 69, 70], "appproxim": 0, "approach": [2, 12, 25, 50], "approxim": [4, 20, 22, 24, 25, 64], "ar": [0, 1, 5, 6, 7, 9, 10, 12, 13, 16, 18, 19, 21, 23, 27, 29, 31, 33, 34, 38, 39, 41, 42, 43, 45, 48, 50, 51, 53, 55, 56, 57, 58, 62, 63, 68, 69, 70, 71, 72, 75, 76, 78], "arang": [0, 20, 23, 24, 25, 26], "arbitrari": 74, "architectur": 45, "aren": [18, 47], "arg_a": 64, "argmax": 39, "arguabl": 68, "argument": [50, 69], "around": [4, 7, 56, 57, 63], "arrai": [14, 25], "arriv": [3, 61, 64, 65], "art": [9, 19, 45], "artifici": 21, "ascent": 11, "ased": 74, "asid": 21, "ask": [2, 28, 68, 73], "assign": 74, "associ": [45, 64], "assum": [17, 22, 70, 74, 75], "ate": 45, "attempt": 8, "attent": 46, "attn_appli": 39, "audio": [18, 68], "aussian": 74, "auto": [17, 45], "autoregress": 43, "auxiliari": 77, "avail": 41, "averag": [20, 25, 35, 39, 47, 70], "avoid": 23, "awai": [28, 51, 74], "axi": [25, 39, 45], "b": [22, 31, 43, 70, 74], "ba": 22, "back": [38, 47], "bad": [13, 18, 53, 63], "balanc": 75, "ball": 60, "banana": 29, "barto": 64, "base": [1, 2, 7, 9, 10, 29, 34, 42, 45, 46, 55, 58, 74, 75], "basic": [0, 3, 4, 7, 14, 20, 21, 30, 45, 63, 64, 68, 70, 72], "bat": 13, "batch": [55, 64], "bear": 19, "beauti": 14, "becaus": [0, 4, 9, 10, 14, 17, 19, 20, 22, 23, 25, 28, 29, 33, 37, 38, 45, 46, 47, 48, 50, 52, 53, 55, 58, 61, 62, 64, 65, 74], "becom": [0, 43, 50], "been": 68, "befor": [0, 33, 47, 63, 69], "begin": 3, "behavior": [19, 63, 65], "behind": [0, 3, 41], "being": [8, 11, 14, 21, 42, 45, 51, 53, 55, 65, 66], "believ": 19, "belli": 10, "below": [24, 25], "benefit": 42, "bert": 46, "besid": 7, "best": [6, 15, 18, 35, 64], "better": [6, 8, 13, 14, 16, 46, 59, 65, 66, 68, 73], "between": [12, 13, 56, 61, 63, 75, 78], "bia": [22, 31], "bicycl": 12, "big": [0, 12, 24, 30, 33, 43, 48, 50, 52, 53, 57, 64, 66, 74], "bigger": [0, 46, 47, 48, 49, 59, 66], "billion": 66, "binari": 18, "biomed": 69, "birthdai": 65, "bisexu": 70, "bit": [0, 9, 17, 20], "black": 70, "blade": 60, "bleu": 5, "blind": 2, "block": [30, 35, 41], "bmatrix": 3, "bob": 45, "bodi": 61, "book": 64, "born": [2, 68], "both": [18, 37, 45, 47, 68, 78], "bother": 15, "brain": [7, 37, 61], "branch": [21, 63], "bright": 70, "build": [7, 30, 41], "c": 74, "calcul": [4, 45, 50, 65], "call": [2, 4, 6, 7, 12, 14, 18, 19, 20, 21, 23, 26, 27, 31, 38, 43, 45, 51, 52, 55, 60, 63, 64, 71], "callback": 30, "calm": 21, "can": [2, 3, 4, 6, 7, 8, 9, 12, 13, 16, 18, 19, 20, 21, 22, 25, 27, 28, 29, 30, 31, 34, 41, 42, 43, 45, 46, 47, 50, 54, 55, 56, 57, 58, 60, 61, 63, 64, 65, 68, 70, 72, 74, 75], "cancel": 55, "cannot": 17, "capabl": 20, "capsul": 16, "captur": 14, "car": [1, 69], "carbon": [57, 63], "care": [0, 22, 35, 60], "carefulli": 53, "case": [2, 4, 9, 10, 14, 20, 21, 22, 39, 41, 42, 43, 45, 47, 50, 61, 72, 75], "cat": [0, 7, 57, 70], "categor": 53, "categori": 68, "caus": [53, 63], "caveman": 14, "celebr": 65, "center": 74, "certain": [5, 6, 47, 74], "certainli": 21, "chain": [22, 50], "champion": 46, "chanc": [4, 11, 51, 65], "chang": [10, 31, 45, 47, 55, 56, 57, 63, 69], "channel": 9, "chapter": [55, 66], "charact": [30, 43], "characterist": 10, "cheap": 36, "check": 21, "choos": [20, 57, 64, 73], "clarifi": 12, "class": [16, 30, 74, 75, 78], "classic": 68, "classif": [16, 19, 27, 41, 72], "classifi": [11, 16, 18, 56, 57, 68, 70], "clearer": 25, "clip": 55, "clone": 61, "close": [0, 18, 24, 47, 51, 64, 72, 74, 78], "closer": [6, 25, 39, 47, 74], "closest": 74, "cluster": [10, 16], "cnn": 27, "co": [3, 4], "code": 21, "colder_max": 25, "collect": 55, "color": 68, "combat": 9, "combin": [20, 74], "come": [0, 2, 3, 9, 39, 45, 71], "command": 19, "commit": 47, "common": [2, 6, 19, 20, 27, 34, 53, 59, 63, 68], "commonli": 35, "compact": 14, "compani": 6, "compar": [5, 6, 14, 23, 36, 37, 64, 68], "competit": 18, "complet": [39, 41, 68], "complic": [0, 3, 19, 22, 23, 36, 53, 58, 64, 66], "compon": [31, 45], "compos": [3, 4, 74], "compress": [14, 17], "compromis": 42, "comput": [4, 14, 19, 21, 27, 29, 47, 48, 50, 53, 57, 63, 64], "con": 58, "concept": 21, "concis": 21, "condit": [43, 60], "confid": 16, "confus": [21, 36], "congratul": 14, "consid": [21, 50, 56, 58], "consist": [0, 9, 15, 63], "consolid": 12, "constrain": [12, 17], "construct": [22, 37], "consum": 53, "contain": [43, 45], "context": 4, "continu": 46, "contrari": 19, "contrast": 13, "control": [53, 61], "conv2d": 30, "conveni": 30, "converg": 54, "convert": [9, 14, 29, 30, 43], "convolut": [30, 34, 35], "cool": [45, 55], "correct": [2, 10, 19, 42, 57], "correspond": [17, 43, 64], "could": [0, 49, 64, 66, 69, 75], "countri": 68, "cours": [9, 66], "cousin": 69, "covari": 20, "cover": [14, 21, 78], "creat": [0, 15, 18, 19, 20, 30, 72], "cross": 51, "crucial": [14, 39], "crunch": 10, "ctifi": 23, "current": [0, 50, 62, 65], "curri": 63, "custom": 30, "d": [3, 4, 18, 43, 74], "dai": 63, "dark": 70, "data": [5, 7, 8, 13, 14, 16, 18, 19, 20, 28, 30, 39, 45, 46, 47, 53, 55, 58, 69, 74, 75, 77, 78], "dataset": [13, 45, 47, 69, 77, 78], "deaf": 2, "deal": [0, 9, 21], "debug": 53, "decad": 12, "decai": 65, "decept": [21, 53], "decid": [7, 43, 46, 63, 68], "decis": [0, 1, 6, 7, 10, 61, 70], "decod": [14, 16, 43, 68], "decompos": [3, 22], "decompress": 14, "deep": [0, 3, 4, 6, 9, 10, 21, 22, 33, 50, 73], "deeper": 74, "def": [20, 23, 24, 25, 26, 30, 39], "defeat": 41, "defin": [3, 22, 30, 64, 65], "definit": [17, 48, 55], "demonstr": 3, "denomin": 20, "denot": 4, "dens": [9, 15, 31], "densiti": 74, "depend": [0, 15, 56], "deploi": 66, "depth": 50, "deriv": [3, 51], "descent": [5, 52], "describ": [60, 63, 76], "design": [57, 63], "desir": [2, 39, 53, 70], "despic": 36, "despit": [12, 16], "destroi": 12, "detach": 31, "determin": [62, 64, 65, 74], "develop": [14, 55, 63], "deviat": 17, "devic": [8, 9, 66], "df": [50, 52], "di": 63, "did": 70, "differ": [0, 1, 8, 12, 14, 16, 19, 22, 27, 31, 39, 45, 47, 55, 56, 57, 58, 61, 74, 78], "differenti": [0, 75], "difficult": [9, 18, 33, 37, 46, 52, 58], "digit": 68, "dimens": [0, 14, 15, 25, 27, 29, 31, 51], "dimension": [0, 3], "dinner": 63, "direct": [4, 10, 12], "directli": [5, 10, 16, 27, 29, 64], "discard": 58, "discrimin": [18, 19, 68, 78], "discuss": [2, 45], "disk": 9, "displai": 11, "distanc": 12, "distant": 65, "distil": 9, "distinct": 75, "distinguish": 75, "distribut": [17, 20, 25, 43, 47, 69], "dive": 21, "divers": 49, "divid": 62, "dl": 21, "do": [0, 4, 6, 8, 11, 12, 15, 30, 39, 45, 46, 52, 53, 59, 71, 72, 73, 74, 78], "document": [68, 69], "doe": [5, 7, 9, 10, 12, 14, 15, 21, 22, 30, 39, 43, 46, 50, 51, 55, 64, 78], "doesn": [8, 10, 22, 46, 50, 53, 55], "dog": [0, 7, 57, 70], "domain": 8, "domin": 45, "don": [0, 4, 6, 19, 21, 22, 29, 30, 34, 35, 46, 48, 49, 51, 52, 56, 75, 78], "dope": 53, "dot": [12, 27], "doubt": 51, "down": [15, 50, 51], "downsid": 9, "drastic": [28, 35], "drive": 1, "drop": [28, 48], "dropout": 48, "du": 50, "due": [24, 34, 50], "duh": 2, "dure": [15, 17, 68], "dx": [50, 52], "dy": 50, "e": [22, 24, 25, 43, 55], "e_": 62, "each": [0, 13, 20, 22, 30, 43, 45, 55, 58, 62, 64, 65, 74, 75, 78], "earli": 63, "earlier": [50, 74], "earn": 12, "earth": [57, 63], "easi": [3, 10, 13, 18, 21, 30, 53, 58, 64, 65, 75], "easier": [8, 9, 16, 47], "easili": [22, 46, 72], "eat": 63, "eaten": 45, "edg": [27, 34, 66], "effect": [48, 54], "effici": [9, 13, 58, 66], "either": [12, 21, 45, 50, 70], "elon": 21, "els": [64, 70], "embed": [30, 43, 45], "emili": 70, "emphas": 25, "employe": 6, "encod": [14, 17, 43, 68], "encount": [18, 47, 51, 53, 65], "encourag": [16, 48, 66], "end": [3, 9, 18, 64, 65, 66, 74], "english": 68, "enhanc": 63, "enough": [0, 4, 14, 20, 22, 41, 47, 48, 64, 66, 68], "ensiti": 74, "ensur": [17, 72], "enter": 63, "entir": [16, 47], "entri": [47, 58, 78], "environ": [13, 56, 57, 58, 61, 62, 63, 65, 68, 69], "epsilon": 64, "equal": [21, 39, 59], "equat": [62, 64], "equival": [55, 62], "error": 53, "escap": 37, "especi": [42, 51], "essenti": [0, 1, 16, 41, 54, 55], "eta": [4, 52, 64], "etc": [14, 18, 27], "evalu": [5, 6, 48], "even": [2, 8, 9, 18, 19, 25, 42, 51, 57, 72, 75], "evenli": 75, "event": [20, 46], "eventu": 55, "everi": [0, 1, 12, 14, 22, 35, 45, 50, 74, 75], "everydai": 9, "everyth": 60, "everytim": 38, "everywher": 30, "exactli": [22, 66], "exam": [6, 72], "exampl": [0, 9, 11, 13, 14, 16, 19, 22, 27, 29, 31, 35, 39, 47, 48, 50, 57, 60, 61, 63, 65, 68, 69, 72], "exce": [24, 25], "except": [41, 60], "exist": [4, 10, 12, 51, 74], "exp": [20, 24, 25, 26, 39], "expand": 22, "expans": 4, "expect": [12, 55, 62, 65], "expens": 47, "experi": [15, 18], "explain": 74, "explan": 3, "explanatori": 34, "explicit": 52, "explicitli": 52, "explod": [23, 33], "explos": [42, 46], "expon": 20, "extent": 41, "extract": [41, 68], "extractor": [46, 68], "extrem": [8, 42, 50, 51], "ey": 7, "f": [3, 4, 22, 45, 52], "f1": 5, "face": [18, 53, 60], "facebook": 41, "fact": [22, 24, 39, 41, 45, 55], "factor": [39, 50, 55, 65], "fail": 72, "fair": 41, "fairli": 10, "fake": 18, "fall": [68, 73, 74], "familiar": 3, "famou": 55, "fanci": 30, "far": 9, "farther": 74, "fashion": [46, 52], "fast": [8, 9, 13, 20, 23, 75], "faster": [8, 9, 13, 36, 46, 47, 52, 54, 64], "fear": [21, 51], "feasibl": [9, 15], "featur": [27, 29, 41, 46, 68, 74, 75], "fed": 38, "feed": [45, 68], "feel": [0, 3, 28, 63, 68], "few": [19, 20, 41, 48, 57, 75], "fewer": 35, "field": 45, "figur": 2, "file": 21, "filter": [9, 21, 30, 34], "final": 65, "find": [9, 13, 21, 42, 52, 62, 70, 72, 76, 78], "finetun": 52, "finger": 51, "finish": 42, "first": [3, 7, 13, 14, 22, 41, 43, 45, 46, 47, 62, 66, 72], "fish": 10, "fit": [8, 9, 74], "five": 7, "float": [9, 29], "flow": [14, 15, 48], "focu": [3, 39], "focus": [0, 3, 13, 21, 35, 63, 69], "follow": [0, 10, 12, 19, 23, 45, 52, 53, 55, 68, 73, 74], "fool": 18, "footprint": [57, 63], "foreign": 68, "forev": 21, "forget": 12, "form": [4, 74], "formal": [61, 65], "format": [9, 14], "formula": [52, 62], "forth": 47, "forward": [21, 30, 52], "found": [57, 72], "foundat": 65, "frac": [0, 3, 4, 22, 24, 25, 50, 52, 55, 62, 68], "free": [0, 3], "freez": 66, "frequent": 23, "fret": 53, "from": [0, 4, 13, 18, 19, 20, 21, 23, 24, 25, 26, 30, 31, 35, 39, 45, 46, 47, 48, 50, 51, 55, 57, 61, 68, 70, 71, 73], "front": 27, "frozen": 66, "full": [45, 68], "function": [0, 1, 3, 7, 13, 16, 23, 24, 25, 26, 30, 51, 52, 56, 59, 61, 62, 63], "funk": 68, "funni": 20, "further": 22, "futur": [46, 55, 59, 62, 63, 64, 65], "futurist": 61, "g": [18, 62, 74], "g_": [64, 65], "g_t": 64, "gain": 69, "game": [1, 18], "gamma": [64, 65], "gan": [19, 68], "garbag": 19, "gaussian": [17, 74], "gener": [4, 11, 16, 17, 20, 25, 35, 42, 43, 45, 48, 55, 64, 66, 74], "get": [0, 8, 9, 12, 18, 24, 25, 41, 50, 51, 53, 59, 63, 64, 65, 72], "github": 21, "give": [4, 14, 21, 68], "given": [2, 13, 20, 60, 64, 70, 71, 75], "global": [13, 45], "gloomi": 75, "go": [3, 18, 22, 39, 48, 50, 60, 71, 75], "goal": [13, 30], "goe": [10, 53], "good": [0, 1, 3, 5, 6, 13, 14, 16, 17, 18, 19, 20, 30, 38, 41, 54, 59, 63, 70, 72, 75], "googl": 21, "gorilla": 68, "gough": 19, "gpu": [9, 47], "grad_fn": [30, 31], "gradient": [5, 11, 12, 23, 29, 33, 37, 42, 46, 47, 51, 52, 54, 55], "grasp": [0, 3, 21], "great": 9, "greedi": 64, "greedili": 64, "group": [74, 75], "guess": [20, 73], "h": [43, 72], "ha": [3, 5, 10, 12, 17, 18, 20, 22, 47, 51, 63, 64, 68, 69, 75], "had": 33, "hair": 72, "half": [0, 9, 21, 42], "hand": [3, 7, 19, 31, 50, 78], "handbook": 21, "handi": 3, "happen": [20, 31, 38, 49, 53, 57, 64], "happi": 63, "hard": [12, 30], "have": [0, 1, 2, 8, 10, 11, 12, 14, 18, 19, 20, 21, 22, 29, 30, 34, 35, 45, 46, 48, 49, 50, 51, 53, 57, 58, 61, 62, 63, 64, 65, 66, 68, 69, 70, 74, 77, 78], "hd": 68, "he": 10, "head": 10, "heart": 70, "heat": 53, "heavi": 21, "height": 35, "hello": 43, "help": [10, 12, 13, 15, 16, 21, 22, 30, 33, 37, 47, 48, 54, 55], "her": 10, "here": [0, 27, 55], "heurist": 70, "hi": 10, "hidden": [22, 23], "high": [0, 14], "higher": [0, 28, 29, 47, 65], "highli": 36, "hinder": 47, "histori": 58, "hood": [1, 19], "hope": [13, 51], "hopefulli": 75, "host": 21, "hour": 21, "how": [5, 6, 7, 8, 9, 10, 17, 22, 29, 30, 39, 43, 55, 56, 63, 65, 71, 73, 74], "howev": [0, 3, 4, 5, 8, 10, 12, 13, 15, 17, 18, 21, 22, 41, 43, 45, 46, 47, 48, 51, 52, 57, 59, 66, 68, 72], "huge": [10, 12, 33, 50, 51, 52], "human": [2, 7, 10, 12, 14, 18, 19, 37, 46, 61, 63, 68], "hung": 21, "hurt": [9, 60], "hyper": 49, "hyperparamet": 53, "i": [2, 3, 5, 8, 9, 10, 11, 12, 14, 16, 17, 18, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 34, 36, 37, 38, 39, 41, 42, 43, 46, 48, 49, 50, 53, 54, 56, 58, 59, 60, 61, 62, 65, 68, 70, 71, 72, 73, 74, 75, 76], "idea": [2, 21, 37, 41, 45, 74, 75], "ident": 30, "ife": 12, "ignor": 43, "imag": [0, 2, 10, 14, 15, 16, 17, 18, 19, 27, 30, 34, 68, 70, 72, 73], "imagin": [0, 3, 64], "impact": 63, "import": [0, 8, 10, 11, 20, 23, 24, 25, 26, 30, 31, 39, 46, 47, 74], "improv": [10, 13, 28, 33, 46], "incent": 19, "includ": [34, 35, 46], "incom": [55, 61, 62, 64, 65], "increas": [14, 55], "incred": 21, "inde": [45, 68], "independ": 74, "index": 72, "indic": 45, "individu": [35, 47], "induc": 48, "inear": 23, "ineffect": 53, "ineffici": 58, "inf": 0, "infer": 45, "infin": 50, "info": 60, "inform": [4, 14, 15, 17, 21, 41, 45, 70, 75], "ing": 53, "inher": 74, "initi": [13, 14, 18, 41, 52, 63, 74], "inlin": [0, 20, 23, 24, 25, 26, 39, 47], "inner": 48, "input": [0, 1, 2, 7, 11, 13, 14, 15, 19, 20, 22, 23, 27, 28, 30, 31, 33, 34, 35, 36, 37, 38, 42, 43, 45, 47, 64, 66, 68, 69, 70, 71, 72, 76], "inspir": 36, "instanc": 4, "instead": [13, 21, 26, 45, 64, 72], "integ": [9, 29, 56], "intellig": 21, "intend": 46, "interact": [58, 63], "interchang": 21, "interest": [45, 55], "intern": 52, "internet": [9, 21], "interv": 0, "intoler": 53, "intro": 64, "introduc": [19, 33, 37, 45, 69, 74], "intuit": [0, 3, 65], "inv_exp": 26, "involv": 58, "isn": [0, 12, 30, 45, 47, 63], "issu": [21, 33, 37, 45, 47], "issubclass": 30, "iter": 47, "its": [9, 10, 12, 16, 18, 25, 30, 41, 43, 47, 57, 60, 61, 63, 65, 74], "itself": [41, 42, 45, 47, 56], "ixur": 74, "job": [0, 6, 16, 18, 21, 66, 68], "joke": 21, "just": [0, 2, 4, 6, 8, 9, 13, 19, 21, 30, 31, 46, 50, 53, 68, 72, 76], "keep": [21, 39, 46, 69], "keepdim": [25, 39], "kei": [39, 53, 57], "kera": 31, "kind": [27, 36, 37, 41, 45, 46, 47, 74], "knife": 60, "knn": 10, "know": [1, 2, 3, 4, 6, 8, 10, 19, 20, 42, 45, 60, 64, 69, 75], "knowledg": [9, 12, 69], "known": 56, "l": [12, 23, 43, 64], "l1": 48, "l2": 48, "label": [0, 11, 16, 19, 42, 47, 69, 70, 72, 73, 74, 77, 78], "land": 21, "languag": [39, 43, 46, 68, 76, 78], "larg": [9, 39, 46, 50, 51, 53], "larger": [9, 20, 25, 51], "last": [18, 22, 25, 39], "latent": [14, 16, 17], "later": [0, 2, 45, 50, 74], "layer": [0, 9, 14, 15, 16, 22, 23, 36, 37, 41, 45, 48, 50, 55], "le": 65, "lean": 69, "learn": [0, 2, 3, 4, 5, 6, 9, 10, 14, 16, 17, 19, 22, 47, 49, 73, 74], "learner": 21, "learnt": 57, "least": [4, 45], "lee": 21, "left": 74, "len": 20, "less": [8, 9, 14, 36, 50, 51, 58, 65], "let": [0, 3, 22, 25, 30, 43, 47, 53, 70], "level": 43, "leverag": 21, "life": 65, "lifespan": 13, "lifetim": 12, "light": 2, "like": [0, 2, 6, 7, 10, 14, 15, 19, 20, 21, 23, 26, 28, 30, 31, 34, 35, 36, 38, 45, 46, 50, 51, 52, 57, 62, 68, 70, 75, 77], "limit": [22, 26], "line": 0, "linear": [9, 16, 22, 27, 30, 41, 45], "linspac": 47, "list": [3, 29], "liter": 22, "littl": [0, 17, 34, 47, 64, 77], "live": 65, "ll": [0, 2, 14, 21, 45, 48, 53, 72], "local": [27, 51, 66], "locat": [13, 52, 74], "log": 62, "logit": 55, "long": [0, 21, 45, 46, 56], "look": [1, 2, 3, 10, 14, 15, 19, 45, 53, 62, 75], "loss": [4, 13, 19, 48, 51, 52, 59, 64], "lost": 15, "lot": [0, 9, 13, 21, 29, 30, 35, 36, 41, 45, 48, 50, 63, 75], "love": 10, "lower": [6, 14], "lowest": 15, "lstm": 36, "luck": 4, "luster": 74, "m": [3, 14, 31, 74], "machin": [0, 2, 7, 8, 10, 12, 14, 19, 39, 43, 47, 53, 63, 68, 70, 74], "made": [1, 6], "magnitud": 16, "mai": [0, 1, 3, 18, 21, 47, 48, 50, 51, 53, 60, 71], "main": 9, "mainli": [21, 63, 66], "major": 70, "make": [0, 1, 7, 8, 9, 10, 16, 25, 28, 39, 43, 46, 47, 48, 49, 50, 53, 54, 55, 56, 57, 61, 63, 64, 68, 69, 70, 72, 78], "maml": 13, "mammal": 68, "mani": [4, 9, 13, 16, 18, 20, 21, 22, 30, 38, 45, 46, 50, 53, 57, 58, 70, 71, 74], "manner": [15, 66], "map": [0, 10, 15, 31, 70, 72], "market": 72, "marvel": 19, "mask": [39, 76, 78], "massiv": 46, "math": [21, 55, 61, 62, 64, 65], "mathemat": [0, 3, 12, 58], "matmul": 31, "matplotlib": [0, 20, 23, 24, 25, 26, 39, 47], "matric": [9, 22, 31], "matrix": [9, 20, 22, 31], "matter": [0, 9, 51], "max": [22, 23, 25, 35, 64], "maxim": [4, 11, 59, 62, 65, 75], "maximum": [12, 23, 24, 25, 35, 51], "mayb": 18, "mdp": 63, "me": [14, 30, 36], "mean": [9, 10, 13, 14, 19, 20, 22, 27, 30, 35, 39, 45, 46, 47, 51, 55, 65, 68, 72, 75], "meaningless": [22, 53], "measur": [1, 6, 47, 63, 68], "mechan": [36, 39, 45], "medic": 68, "memor": 12, "memori": [9, 12], "mention": 63, "mere": 56, "merg": 9, "method": [3, 4, 9, 12, 13, 42, 55, 76, 77], "metric": 6, "might": 69, "mimic": 7, "mind": [10, 19, 46], "minim": [13, 20, 59], "minimum": [13, 51], "mirror": 34, "mission": 76, "mix": 20, "ml": [13, 21, 53], "mlm": [76, 78], "mnist": [16, 68], "mobil": 8, "mode": 45, "model": [3, 4, 5, 6, 10, 11, 13, 15, 27, 28, 30, 33, 34, 39, 41, 42, 43, 45, 46, 53, 54, 55, 56, 57, 58, 59, 60, 63, 68, 69, 70, 71, 72, 73, 76, 77, 78], "modifi": [11, 12, 63, 65], "modul": 30, "momentum": 54, "monkei": 68, "more": [0, 3, 8, 9, 10, 12, 14, 17, 18, 22, 23, 25, 28, 30, 39, 48, 49, 50, 52, 55, 58, 59, 64, 65, 66, 69, 74, 75], "most": [3, 4, 10, 11, 12, 14, 15, 16, 21, 23, 27, 34, 39, 47, 53, 55, 58, 63, 68, 74, 77], "mostli": [16, 33], "move": [4, 10, 34, 52, 56], "mozart": 19, "mu": [20, 47, 68], "much": [8, 10, 14, 22, 25, 28, 36, 46, 47, 49, 52, 53, 58, 65, 66, 73], "multi": [3, 25], "multipl": [8, 10, 12, 14, 20, 22, 61, 68, 74], "multipli": [39, 45, 62], "music": [2, 19, 68], "musk": 21, "mutat": 45, "my": 28, "n": [0, 20, 31, 74], "nabla": [62, 64], "name": [10, 63, 71], "narrow": 47, "natur": [34, 71, 75, 76], "necessarili": [42, 46], "need": [1, 4, 13, 15, 18, 19, 43, 46, 49, 72, 75], "neg": [12, 23, 24], "nerv": 21, "net": 51, "network": [9, 15, 16, 18, 22, 23, 27, 29, 30, 33, 36, 37, 38, 55, 62, 66], "neural": [22, 27, 29, 30, 33, 37, 38, 43, 50], "neuron": 0, "never": [0, 2, 4, 12, 22, 24, 25, 68, 69], "new": [4, 9, 13, 15, 18, 20, 38, 45, 55, 56, 61, 68, 69], "next": [38, 42, 43, 46, 64, 65, 71, 72, 73], "nice": 75, "nit": 23, "nmt": 43, "nn": [30, 31], "node": [0, 48], "nois": 17, "noisi": [17, 28], "non": [15, 62], "norm": [47, 50], "normal": [12, 17, 19, 20, 45, 55], "notat": 31, "noth": [30, 55, 57], "notic": [0, 14, 26, 43, 55, 59, 62, 64, 72], "now": [0, 8, 25, 28, 30, 46, 68, 71], "nowadai": 21, "np": [0, 20, 23, 24, 25, 26, 39, 47], "num": 39, "num_gaussian": 20, "number": [0, 2, 3, 4, 9, 10, 16, 19, 20, 22, 23, 24, 29, 39, 47, 50, 53, 59, 60, 64, 68, 72, 73, 74], "numer": [10, 20], "numpi": [0, 20, 23, 24, 25, 26, 39, 47], "o": [43, 45], "object": [5, 7, 60, 70], "observ": [39, 47, 58, 60, 61, 63, 65], "obtain": [63, 75], "obviou": [3, 21], "obvious": 2, "occupi": 70, "odel": 74, "off": [9, 13, 17], "offlin": 55, "often": [18, 24, 27, 28, 31, 36, 37, 38, 50, 60, 62, 64, 66], "oh": 63, "ois": 74, "ok": 70, "old": [55, 58, 65], "onc": 58, "one": [0, 4, 12, 13, 14, 15, 20, 22, 23, 29, 35, 36, 37, 41, 46, 47, 51, 55, 56, 64, 65, 68, 69, 70, 71, 72, 73, 74], "ones": [9, 18, 53, 66], "oneself": 13, "ong": 12, "onli": [5, 9, 12, 16, 21, 22, 39, 43, 45, 52, 57, 60, 61, 68, 70, 77], "onto": 68, "openai": 55, "oppos": 10, "opposit": [4, 9, 49], "optim": [4, 52, 63], "optimum": 66, "option": [9, 12], "order": [2, 4, 13, 45, 60], "origin": [14, 15, 55], "other": [0, 4, 7, 11, 13, 22, 36, 39, 45, 46, 52, 55, 60, 63, 65, 69, 74, 78], "otherwis": 3, "our": [1, 6, 7, 11, 51, 61, 64], "out": [2, 3, 12, 13, 21, 28, 30, 39, 45, 48, 50, 51, 53, 63, 76, 78], "output": [0, 2, 7, 10, 11, 12, 13, 14, 15, 18, 19, 22, 23, 25, 26, 30, 31, 35, 38, 43, 45, 47, 48, 55, 56, 61, 62, 64, 66, 71, 72], "outsid": [21, 39], "over": [8, 9, 12, 21, 25, 39, 43, 45, 46, 47, 50, 55, 69], "overfit": [28, 49], "overhead": 47, "overli": [47, 53], "owner": 18, "p": [43, 48], "pack": 15, "pad": 30, "paint": [18, 19], "pair": [2, 13, 27, 66, 71], "panda": [10, 11], "paper": [0, 41, 45], "parallel": 46, "paralyz": 48, "paramet": [0, 3, 4, 13, 20, 49, 50, 51, 64, 66], "part": [0, 1, 3, 11, 14, 35, 36, 39, 48, 63, 69, 78], "particular": 13, "partit": 74, "pass": [15, 16, 17, 30, 36, 45, 50, 55, 68, 72], "past": [38, 46, 54], "path": [12, 14, 21], "patial": 74, "pattern": [2, 30], "pdf": 47, "penalti": [12, 48], "peopl": [9, 10, 19, 21, 33, 75], "percentag": 47, "perfectli": [14, 15], "perform": [0, 1, 5, 6, 7, 8, 9, 12, 15, 28, 36, 45, 48, 49, 52, 66, 68, 69, 72, 77], "person": [2, 6, 12, 14, 63], "phenomenon": 51, "photo": [18, 68], "pi": [20, 61, 62], "pi_a": 65, "pictur": 11, "picturesqu": 68, "pile": 20, "pixel": 34, "place": [10, 20, 27, 39], "plai": 1, "planet": 63, "player": 18, "pleas": 21, "plot": [0, 20, 23, 24, 25, 26, 47], "plt": [0, 20, 23, 24, 25, 26, 39, 47], "point": [2, 4, 9, 29, 35, 53, 54, 65, 66, 74, 78], "pool": [12, 27, 30, 61], "popular": [10, 46, 50, 74], "portion": [16, 37, 77, 78], "posit": [4, 22, 60], "possibl": [0, 21, 28, 41, 52, 56, 59, 64, 75], "power": [0, 21, 22, 45, 47, 48], "pplicat": 74, "ppo": 55, "pq": 43, "practic": [15, 47, 48], "pre": [13, 41, 64], "preciou": 64, "precis": 52, "predict": [1, 5, 6, 8, 38, 42, 45, 46, 71, 72, 73, 74], "prefer": [15, 47], "preprocessor": 46, "present": 78, "preserv": [14, 21], "press": 57, "prestigi": 21, "pretrain": [41, 46], "pretti": 3, "prevent": 42, "previou": [12, 37, 55, 62, 69, 71, 72], "previous": [43, 45, 63, 74], "principl": [12, 55], "print": [23, 24, 25, 26, 30, 31, 39, 53, 57, 68], "pro": 58, "probabl": [10, 12, 20, 24, 25, 28, 39, 43, 47, 53, 55, 62, 64, 65, 70, 72, 73, 74], "problem": [19, 22, 47, 50, 63, 69, 70, 72, 73, 74], "procedur": 18, "process": [7, 14, 16, 27, 29, 30, 37, 38, 45, 46, 48, 71, 76], "produc": [9, 18, 20, 45], "product": [8, 12], "profit": 72, "program": 4, "progress": [47, 52], "promin": 4, "pronounc": 25, "properti": [18, 20], "prove": 41, "proven": 0, "provid": [0, 2, 3, 19, 45, 50, 65], "prowess": 19, "publish": 41, "pun": 46, "pure": 45, "purpos": [3, 41], "purposefulli": 48, "put": [9, 30], "pyplot": [0, 20, 23, 24, 25, 26, 39, 47], "pytorch": 30, "q": 43, "qualiti": 5, "quantit": 6, "question": [8, 73], "quickli": 21, "quit": [9, 21, 23, 27, 50, 62], "r": [23, 43], "r_a": [64, 65], "r_i": 62, "rage": 21, "rain": [39, 72, 73, 75], "rais": 68, "randn": [20, 25, 30, 39], "random": [20, 25, 39, 63], "randomli": [41, 64, 76], "rang": [20, 21, 26, 53, 64], "rank": 65, "rate": 4, "ratio": 55, "re": [3, 7, 12, 21, 35, 48, 49, 52, 53, 55, 57, 58, 68], "reach": 75, "react": 61, "read": [21, 68], "readi": 18, "readili": 41, "real": [0, 2, 14, 18, 19, 20, 25, 34, 53], "realli": [0, 10, 12, 13, 15, 18, 22, 33, 34, 38, 48, 50, 56], "realm": 13, "reason": [0, 12, 17, 20, 21, 23, 45, 46, 47, 50, 62, 63, 64], "receiv": [63, 65], "recent": [3, 9], "recogn": 69, "reconstruct": 19, "recurr": [30, 36, 37], "recurs": 65, "red": 29, "reduc": [3, 4, 9, 12, 14, 17, 19, 25, 35, 39, 50, 52, 55, 62], "redund": 39, "refer": [13, 16, 17, 20, 21, 22, 30, 33, 58, 63, 65, 66, 71, 77, 78], "regard": [3, 37], "region": [10, 35, 74], "regress": [19, 45, 56, 57], "regressor": 72, "reinforc": 5, "rel": [20, 48, 49, 75], "relat": [38, 46, 47, 69, 72, 74], "releas": 41, "reli": [4, 10], "relu": [22, 50], "remain": [69, 77], "rememb": [33, 37, 50, 55, 64], "remov": 33, "repeat": [18, 55, 74], "replac": [23, 36], "replic": 66, "repres": [22, 30, 50, 74], "represent": [14, 16, 45], "reptil": 13, "requir": 19, "rescal": 68, "research": 41, "reshap": 30, "residu": 45, "resourc": 21, "respect": 11, "respond": 7, "respons": [53, 54], "result": [4, 9, 18, 20, 21, 27, 46, 55, 74], "retain": [12, 35], "return": [6, 20, 23, 24, 25, 26, 30, 39], "reusabl": 30, "review": 12, "reward": [5, 55, 62, 64], "rich": 47, "ridden": 12, "ride": 12, "right": [0, 3, 8, 13, 20, 45, 46, 51, 63, 68], "rightarrow": [0, 64], "rl": [55, 56, 57, 58, 59, 64], "rnn": [37, 38, 42, 45], "robot": 21, "robust": [17, 28, 55], "roll": [7, 54], "rough": 18, "roughli": 68, "rubbish": 42, "rule": [4, 22, 50, 64, 74, 75], "run": [9, 13, 45], "russia": 68, "russian": 68, "sacrific": 9, "saddl": 53, "sai": [3, 10, 14, 39, 42, 43, 63, 70, 72], "said": [2, 20, 42, 70], "salienc": 10, "same": [0, 2, 3, 13, 14, 15, 17, 19, 22, 50, 58, 64, 66, 68, 69, 72, 74], "sampl": [20, 47], "save": 9, "scalar": [6, 55, 59, 62, 64], "scale": [0, 15, 17, 46, 50, 52, 55], "schedul": 52, "school": [6, 8], "scienc": 9, "scientist": 14, "scipi": 47, "score": [5, 29, 45], "search": [13, 21, 66], "second": [14, 22, 43, 45, 47, 72], "secondli": [7, 21], "section": [0, 3, 8, 19, 20, 37, 55, 69], "see": [0, 3, 7, 9, 14, 22, 23, 25, 31, 38, 39, 45, 46, 55, 62, 64, 69, 74], "seem": [3, 12, 48, 49, 53], "seen": [0, 18, 21, 25, 47, 57, 68, 69], "segment": 0, "select": [35, 53, 57, 64, 74], "self": [30, 34, 45], "semest": 72, "send": 47, "sens": [7, 72], "sent": [45, 47], "sentenc": [14, 39, 42, 45, 76], "separ": [0, 14, 16, 72, 75], "seq2seq": 45, "sequenc": [30, 38, 43, 45, 46, 71], "sequenti": [30, 45], "seri": 4, "set": [5, 18, 22, 57, 59, 60, 75], "sever": [19, 20, 34, 41, 47, 50, 63, 68, 73, 74, 75], "shabbi": 36, "shallow": 50, "shape": [0, 30, 31], "share": [25, 61, 68], "she": 10, "shift": 74, "short": 26, "shortcut": 50, "shorter": 14, "should": [0, 12, 20, 29, 45, 51, 55, 59, 75], "shouldn": [55, 73], "show": [0, 8, 20, 23, 24, 25, 26, 29, 45, 47, 56], "shuffl": 45, "sight": 7, "sigma": [20, 22, 45, 47, 68], "sigmoid": [22, 25, 26, 50], "signific": [43, 45], "sim": 62, "similar": [36, 52, 68, 69, 71], "similarli": 55, "simpl": [0, 9, 22, 23, 53, 68, 74, 75], "simpler": [16, 19, 22, 47, 58], "simplest": 4, "simpli": [0, 3, 4, 9, 10, 12, 15, 19, 20, 22, 33, 43, 46, 47, 74], "simplifi": 22, "sin": [0, 3, 4], "sinc": [0, 21, 62, 65], "sine": 0, "singl": [13, 61], "sit": 51, "size": [4, 9, 14, 17, 25, 30, 35, 36, 39, 50, 52], "skip": [0, 3, 54], "sky": 75, "slash": 9, "slide": 34, "slightli": 52, "slime": 20, "slope": 51, "slow": [9, 47, 51, 53], "slowli": 46, "small": [0, 4, 8, 14, 16, 22, 48, 50, 53, 54, 66, 68, 78], "smaller": [0, 9, 45, 46, 47, 48, 66], "smallest": [14, 15], "smart": [2, 7], "smell": 7, "smooth": 0, "snapchat": 21, "so": [2, 4, 7, 8, 9, 10, 11, 12, 13, 15, 17, 18, 19, 20, 21, 22, 36, 39, 41, 43, 45, 46, 48, 51, 55, 56, 57, 59, 62, 63, 64, 65, 68, 75], "softer": 25, "softer_max": 25, "softmax": [16, 39, 50, 55], "solut": [3, 48, 52, 66], "solv": [21, 48, 53, 63, 68, 69, 70], "some": [1, 7, 9, 10, 13, 17, 18, 22, 35, 36, 37, 38, 39, 41, 45, 51, 52, 63, 66, 68, 69, 72, 75], "someth": [2, 12, 19, 30, 35, 53, 68, 71], "sometim": [6, 8, 10, 12, 21, 27, 31, 42, 53], "song": 18, "sort": 52, "sound": [2, 7, 51, 55, 70], "sourc": [21, 69], "space": [9, 14, 43, 74], "spam": 41, "spars": 9, "speak": [0, 48, 51], "special": [10, 12, 20, 30, 34, 35, 36, 37, 55], "specif": [62, 76], "speed": 33, "spend": 47, "spit": 30, "split": 75, "sqrt": [20, 47], "stabil": 33, "stabl": 58, "stack": [22, 45], "stai": [12, 69], "stand": 64, "standard": 17, "star": 21, "start": 46, "stat": 47, "state": [9, 45, 56, 57, 58, 61, 62, 64, 65], "statist": 68, "stddev": [17, 20, 68], "steer": 57, "step": [3, 4, 43, 45, 52, 55], "still": [0, 9, 10, 19, 53, 59, 68], "stock": [72, 73], "stone": 10, "stop": 48, "store": [9, 45, 58, 60, 69], "straight": 21, "straightforward": 16, "strategi": 54, "stress": 9, "strive": 19, "structur": [15, 41], "stuck": [51, 53, 66], "student": [6, 66], "stuff": [2, 19], "sub": 13, "subclass": 30, "subset": 21, "subtract": 55, "success": 46, "sudden": 68, "suddenli": 4, "suffer": [46, 50], "suffic": 20, "sum": [20, 25, 39, 65], "sum_a": 65, "sum_exp": [25, 39], "sum_i": 62, "sum_j": [25, 55], "summat": 65, "super": [8, 9, 20, 30, 53], "supervis": [2, 15, 66], "suppos": [0, 15, 22, 64, 65, 68, 74], "sure": [47, 50, 68], "surfac": [0, 4], "surround": 7, "surviv": 21, "sutton": 64, "swim": [12, 61], "switch": 3, "symmetr": 15, "symmetri": 45, "system": [1, 16, 21, 30, 53], "t": [0, 4, 6, 8, 10, 18, 19, 21, 22, 25, 29, 30, 34, 35, 39, 42, 43, 45, 46, 47, 48, 49, 51, 52, 53, 55, 56, 63, 64, 73, 75, 78], "tab": 39, "take": [0, 3, 4, 6, 7, 9, 14, 21, 27, 30, 35, 43, 45, 52, 55, 56, 59, 61, 63, 64, 65, 71, 75], "takeawai": 52, "taken": [56, 68], "talk": 1, "tanh": [23, 50], "target": [13, 18, 31, 66, 69], "task": [1, 6, 13, 30, 46, 48, 49, 53, 57, 76], "tast": 7, "taylor": 4, "teacher": 66, "techniqu": [4, 10, 48], "tell": [4, 11, 14, 18, 19, 60, 68, 75], "temperatur": 25, "tend": [10, 42, 66], "tendenc": 66, "tensor": [30, 31, 43, 60], "tensorflow": 3, "term": [12, 15, 21], "termin": [63, 65], "terrain": 54, "terribli": 48, "test": 28, "text": [2, 27, 29, 30, 38, 46, 68], "than": [0, 8, 10, 14, 17, 20, 29, 39, 47, 48, 58, 64, 66, 74], "thei": [6, 15, 19, 21, 27, 29, 45, 57, 68, 69, 74, 78], "them": [4, 19, 21, 64, 68, 69], "theme": 70, "themselv": 78, "theori": [21, 47, 58], "therefor": [5, 15], "theta": 4, "thi": [0, 2, 3, 4, 6, 8, 9, 10, 11, 12, 18, 20, 30, 31, 39, 42, 47, 48, 50, 51, 52, 55, 58, 59, 60, 62, 64, 65, 66, 70, 72], "thing": [6, 9, 10, 13, 18, 21, 22, 28, 37, 38, 45, 46, 50, 57, 59, 60, 63, 64, 69, 72, 74, 75], "think": [0, 7, 10, 14, 15, 18, 19, 30, 68, 72, 73], "thirdli": 21, "those": [4, 5, 9, 21, 29, 39, 43, 46, 47, 53, 68], "though": [0, 9, 19, 22, 51], "thought": [12, 22], "three": [0, 1, 9, 68], "threshold": 0, "through": [13, 14, 15, 16, 17, 21, 45, 46, 50, 65, 68], "throw": [28, 39], "thrown": 68, "thu": 62, "thumb": 4, "tild": 18, "time": [11, 16, 18, 21, 31, 33, 35, 38, 43, 45, 46, 53, 64, 65, 70, 71, 72], "tini": 52, "todai": 71, "togeth": [30, 74, 78], "token": [29, 30, 42, 45, 46, 71], "tolist": 20, "tom": 70, "tomorrow": 73, "too": [0, 3, 21, 22, 30, 36, 37, 42, 43, 48, 49, 53, 55], "toolkit": 31, "top": [21, 22], "topic": [2, 21], "torch": [30, 31], "total": 63, "touch": 7, "toward": [13, 69], "town": 68, "tradit": 13, "tradition": 45, "train": [5, 7, 8, 9, 13, 15, 17, 19, 23, 28, 33, 36, 37, 42, 46, 48, 49, 50, 51, 52, 54, 55, 68, 69, 78], "trainabl": 50, "trainig": 47, "trait": [68, 78], "trajectori": [55, 58], "transfer": [9, 47, 66], "transform": [22, 30, 31, 36, 38, 41, 43], "transit": [56, 63, 64], "translat": 43, "transplant": 72, "treat": [69, 74], "tree": 10, "tremend": 37, "trend": 9, "tri": [4, 11, 18, 21, 59, 63, 64, 65, 68], "trial": 53, "trick": 21, "tricki": 47, "truck": 69, "true": [25, 30, 31, 39, 50], "truli": [0, 22], "trust": 30, "try": [3, 11, 12, 14, 18, 47, 63, 66, 68, 69, 72], "tune": [49, 53], "turn": [3, 16, 28, 45], "twice": 45, "twist": [17, 64], "two": [0, 9, 13, 14, 18, 22, 23, 31, 42, 47, 72, 73, 74, 75], "type": [22, 53, 68], "typic": 23, "u": [1, 4, 7, 10, 11, 18, 22, 23, 47, 56, 68], "ultim": 15, "umbrella": 75, "un": [41, 50], "unabl": 46, "uncertainti": 65, "uncommon": 50, "under": [1, 19], "understand": [2, 7, 8, 10, 14, 21, 22, 29, 39, 45, 53, 75], "undisput": 46, "unimport": 39, "unlabel": [16, 77], "unlik": [45, 47, 51], "unlucki": 53, "unprocess": 37, "unseen": [8, 71], "unsupervis": 2, "until": [14, 65, 74], "untrain": 41, "up": [0, 1, 4, 15, 43, 46, 64, 68], "updat": [12, 13, 47, 50, 52, 53, 54, 55, 58, 59, 62, 63, 64, 77], "upon": 46, "upward": 4, "us": [0, 3, 6, 7, 9, 10, 11, 12, 18, 19, 22, 23, 24, 25, 26, 30, 42, 45, 46, 47, 48, 49, 53, 54, 55, 56, 58, 59, 60, 62, 63, 64, 66, 68, 69, 73, 74, 76, 78], "usag": 9, "useless": 53, "usual": [4, 15, 17, 19, 20, 22, 23, 27, 28, 34, 35, 38, 45, 47, 51, 55, 56, 57, 58, 62, 77, 78], "util": 68, "v": [64, 72], "vae": 19, "valu": [4, 6, 9, 10, 22, 24, 25, 34, 39, 45, 53, 55, 56, 62, 64, 71], "valuabl": 65, "van": 19, "vanilla": [37, 52], "vanish": [23, 33, 46], "vari": 47, "varianc": [47, 55], "vdot": 3, "ve": [57, 68], "vector": [14, 15, 16, 17, 20, 22, 29, 30, 31, 43, 45, 55, 64, 68, 74], "veloc": 60, "veri": [0, 1, 3, 10, 16, 18, 19, 22, 24, 27, 30, 33, 41, 45, 46, 47, 48, 49, 50, 51, 53, 58, 68, 74], "versa": 64, "version": [14, 25, 27, 41, 64], "vice": 64, "video": [2, 18, 38], "viewbackward0": [30, 31], "visual": [27, 51], "voic": [19, 30, 38, 46], "voila": [18, 62], "w": [31, 43], "wa": [7, 14, 63], "wai": [0, 3, 10, 12, 15, 16, 19, 20, 21, 22, 30, 34, 39, 42, 45, 50, 59, 65, 68, 74, 75], "wait": 15, "walk": 8, "want": [0, 3, 6, 10, 15, 19, 20, 21, 22, 26, 28, 29, 31, 33, 34, 35, 41, 43, 45, 50, 52, 53, 60, 64, 69], "wast": 9, "wave": 0, "we": [0, 1, 3, 4, 6, 8, 10, 11, 12, 13, 14, 17, 18, 19, 20, 22, 27, 30, 33, 38, 43, 45, 47, 51, 52, 57, 60, 61, 62, 63, 64, 69, 70, 72, 74, 78], "weak": 46, "weigh": 45, "weight": [9, 12, 20, 22, 25, 31, 35, 39, 48, 55, 58, 65], "weirdli": 14, "well": [1, 4, 6, 8, 10, 14, 15, 45, 47, 48, 49, 53, 69, 72, 74], "what": [1, 3, 4, 14, 19, 42, 43, 45, 46, 56, 61, 68, 69, 70, 73, 75, 76], "wheel": 57, "when": [0, 2, 10, 13, 14, 16, 17, 18, 22, 24, 25, 26, 41, 45, 47, 49, 53, 57, 63, 64, 69, 72, 78], "whenev": 52, "where": [0, 2, 3, 4, 21, 28, 51, 54, 57, 60, 64, 65, 68, 70, 72, 78], "whether": [1, 27, 35, 38, 69, 74], "which": [3, 4, 6, 7, 9, 10, 13, 15, 16, 18, 20, 21, 22, 27, 30, 35, 41, 42, 43, 45, 50, 51, 55, 56, 61, 62, 63, 64, 66, 70, 73, 74, 77], "while": [19, 37, 39, 54, 56, 58, 60, 66, 69, 72, 77], "white": 70, "who": [1, 21, 45], "whole": 47, "whose": 22, "why": [3, 15, 28, 53, 71], "width": 35, "wikipedia": 69, "wildli": 46, "willing": 9, "window": 34, "wire": 69, "wisdom": 8, "wise": 72, "wish": [62, 66], "within": 22, "without": [1, 9, 13, 21, 22, 45], "wonder": [68, 71], "word": [0, 11, 13, 19, 29, 39, 43, 45, 60, 63, 65, 69, 70, 75, 76], "work": [0, 6, 10, 15, 30, 46, 68, 69, 74], "world": [0, 2, 4, 7, 14, 19, 20, 21, 43, 53, 56, 57, 61, 63], "worri": [4, 13, 47], "worth": [59, 73], "would": [19, 21, 22, 25, 28, 41, 43, 55, 56, 60, 65, 68, 70, 75], "wouldn": 12, "written": 55, "wrong": [10, 21, 53], "wx": 31, "x": [0, 3, 18, 20, 22, 23, 24, 25, 26, 30, 31, 39, 47, 52, 65, 68, 71], "x_1": 3, "x_2": 3, "x_i": [25, 55], "x_j": [25, 55], "x_n": 3, "xlim": 47, "y": [0, 3, 20, 23, 24, 25, 26, 30, 71], "y1": 31, "y2": 31, "ye": [5, 8, 15, 47, 56], "year": [12, 46, 65, 72, 73], "yet": [14, 19, 75], "yi": 21, "yield": [21, 47, 48, 59, 63], "ylim": 47, "you": [0, 1, 2, 3, 4, 8, 9, 10, 12, 14, 15, 18, 19, 20, 21, 26, 28, 29, 30, 31, 33, 34, 35, 39, 41, 42, 43, 46, 47, 48, 49, 50, 52, 53, 55, 61, 62, 65, 68, 69, 70, 71, 72, 73, 75], "your": [0, 1, 8, 9, 10, 15, 18, 21, 28, 30, 33, 34, 41, 46, 48, 49, 50, 53, 54, 61, 65, 68, 70, 72, 73], "yourself": [3, 41, 46], "zebra": 10, "zero": [9, 25, 47, 48, 51, 62]}, "titles": ["Approximation models", "Holy Trinity for Machine Learning", "Data", "How Gradients Are Calculated?", "Gradients", "Do loss functions have to be differentiable?", "Loss Function", "Model", "Improvements to a model", "Model Compression", "Explainable AI", "Saliency Maps", "Life Long Learning", "Meta Learning", "AutoEncoder Model", "Auto Encoder Architecture", "Improving Auto Encoders with Semi Supervised Training", "Variational AutoEncoder Model", "Generative Adversarial Models", "Generative Models", "Gaussian Mixture Model", "Introduction", "Activation Functions", "Rectified Linear Unit", "Sigmoid", "Softmax", "Hyperbolic Tangent", "Convolution Layer", "Dropout Layer", "Embedding Layer", "Layers", "Linear Layer", "Calculate gradients for Linear Layers", "Normalization Layer", "Padding Layer", "Pooling Layer", "Gated Linear Unit", "Long Short Term Memory", "Recurrent Layer", "Attention", "Self Attention", "Using Bert without training?", "Teacher Forcing vs Scheduled Sampling vs Normal Mode", "Token", "Training Transformers", "Transformer Block", "Transformer vs RNN", "Batch size", "Overfit", "Underfit", "Gradient Vanishing / Gradient Explosion", "Saddle point", "Learning Rate", "Other Things To Notice", "Optimizer", "Actor Critic", "Action", "Agent", "Online Methods vs Offline Methods", "Reward", "State", "Policy", "Policy Gradient", "Reinforcement Learning", "Q Learning", "Value", "Knowledge Distillation", "Reusing Existing Models", "Transfer Learning and Domain Adaptation", "Transfer Learning vs Domain Adaptation", "Classification", "Auto Regression", "Regression", "Types of tasks", "Clustering", "Decision Tree", "Self Supervised Learning", "Semi Supervised Training", "Unsupervised Learning"], "titleterms": {"": [13, 15, 16, 39], "In": 69, "The": [6, 9, 47, 62, 66], "To": 53, "about": 51, "action": [56, 63], "activ": [22, 50], "actor": 55, "adapt": [68, 69], "add": 48, "adversari": [18, 68], "ae": [15, 16], "affect": 10, "agent": [57, 61, 63], "ai": [8, 10], "aid": 16, "algorithm": 18, "all": [45, 46], "alreadi": 12, "an": [0, 15], "appear": 51, "appli": 62, "approach": 10, "approxim": 0, "ar": [2, 3, 4, 11, 14, 17, 20, 22, 30, 35, 36, 37, 46, 47, 52, 54, 59, 60, 61, 64, 65, 74], "architectur": 15, "area": 8, "attent": [39, 40, 45], "auto": [15, 16, 71], "autoencod": [14, 17], "base": 68, "batch": [47, 53], "befor": 21, "bert": 41, "besid": 53, "better": [0, 17, 64], "between": [15, 65], "big": 47, "bigger": 12, "biggest": 10, "block": 45, "book": 21, "calcul": [3, 32], "can": [0, 15, 52, 53, 62], "certain": 50, "chain": 3, "chang": 12, "choos": [47, 52], "classif": [70, 73], "cluster": [74, 78], "code": [23, 24, 25, 26, 30, 31, 39], "common": [30, 78], "compress": [8, 9], "conflict": 12, "converg": 47, "convolut": 27, "critic": 55, "da": [68, 69], "data": [1, 2, 12, 48, 49], "dbscan": 74, "deal": [48, 49, 50], "decis": [63, 75, 78], "decod": [15, 45], "deep": [56, 57, 59, 60], "deeper": 0, "definit": [23, 24, 25, 69], "descent": 4, "design": 15, "determin": 4, "differ": [13, 15, 52, 68, 69, 77], "differenti": [4, 5], "discrep": 68, "distil": 66, "do": [1, 2, 5, 7, 9, 14, 17, 18, 19, 27, 28, 29, 31, 33, 34, 38, 50, 51, 56, 66, 68, 75], "doe": [3, 20, 23, 24, 25, 26, 28, 31, 45, 47, 48, 49, 70, 71, 72], "domain": [68, 69], "don": [5, 12, 50, 66], "dropout": 28, "embed": 29, "encod": [15, 16, 45], "enough": 46, "exactli": 6, "exampl": [3, 5], "exist": 67, "explain": [8, 10], "explod": 50, "explos": 50, "far": 53, "flow": 66, "forc": 42, "from": [66, 69, 77], "function": [4, 5, 6, 22, 50, 64, 65], "gan": 18, "gate": 36, "gaussian": 20, "gener": [14, 18, 19], "get": 10, "gmm": [20, 74], "good": 46, "gradient": [3, 4, 10, 32, 50, 53, 62], "gru": 36, "happen": [48, 50], "hard": 53, "have": 5, "hierarchi": 74, "holi": 1, "how": [0, 1, 3, 4, 12, 13, 14, 15, 18, 19, 20, 21, 23, 24, 25, 26, 31, 45, 47, 48, 49, 50, 52, 53, 64, 69, 70, 72, 75, 77], "hyper": 48, "hyperbol": 26, "i": [0, 1, 4, 6, 7, 15, 21, 45, 47, 51, 52, 55, 57, 63, 64, 66, 69, 77], "import": [63, 65], "improv": [8, 16], "increas": 49, "input": 10, "introduct": [21, 23, 24, 25, 26], "issu": 53, "its": 15, "just": 10, "k": 74, "kd": 66, "know": 12, "knowledg": 66, "last": 47, "latent": 15, "layer": [27, 28, 29, 30, 31, 32, 33, 34, 35, 38], "learn": [1, 8, 12, 13, 21, 52, 53, 56, 57, 59, 60, 63, 64, 68, 69, 76, 78], "life": [8, 12, 13], "linear": [23, 31, 32, 36], "lll": 12, "long": [8, 12, 13, 37, 47], "look": [20, 23, 24, 25, 26], "loss": [1, 5, 6], "lot": 47, "louder": 56, "lr": 52, "lstm": 37, "machin": [1, 21], "main": 10, "make": [12, 75], "map": 11, "markov": 63, "mayb": 15, "mean": [17, 49, 71, 74], "memori": 37, "meta": [8, 13], "method": [58, 68, 74, 78], "mix": 12, "mixtur": 20, "mode": 42, "model": [0, 1, 7, 8, 9, 12, 14, 17, 18, 19, 20, 47, 48, 49, 66, 67], "most": 78, "much": 12, "my": [15, 52], "need": [2, 5, 6, 7, 9, 45, 66, 68], "network": 50, "new": 12, "norm": 33, "normal": [33, 42, 50], "notic": 53, "offlin": 58, "old": 12, "onli": 47, "onlin": 58, "optim": [53, 54, 55], "other": 53, "overfit": [48, 53], "pad": 34, "paramet": [48, 52], "part": [10, 15], "perform": 16, "point": 51, "polici": [55, 61, 62, 63], "pool": 35, "posit": 45, "possibl": 47, "process": 63, "proxim": 55, "prune": 9, "pytorch": 3, "q": 64, "quantiz": 9, "rage": 46, "rate": [52, 53], "reconstruct": 68, "rectifi": 23, "recurr": 38, "reduc": [48, 49], "regress": [71, 72, 73], "regular": 48, "reinforc": 63, "relat": 65, "relu": 23, "rememb": 47, "remov": 10, "residu": 50, "reus": 67, "reward": [59, 63, 65], "rl": [61, 63, 65], "rnn": 46, "rule": 3, "saddl": 51, "sai": 15, "salienc": 11, "same": [52, 61], "sampl": 42, "schedul": 42, "scratch": 66, "see": [10, 47], "seen": 53, "self": [40, 76, 78], "semi": [16, 77, 78], "share": 15, "short": 37, "should": [15, 47, 52], "sigmoid": 24, "simpl": [62, 64, 69], "size": [47, 48, 49, 53], "small": 47, "so": [3, 47, 53], "softmax": 25, "some": [30, 49], "speak": 56, "start": 21, "state": [60, 63], "structur": 9, "summari": [9, 53], "supervis": [16, 76, 77, 78], "symmetri": 15, "system": 10, "t": [5, 12, 50, 66], "take": [15, 47], "tangent": 26, "tanh": 26, "task": [12, 73], "teacher": 42, "techniqu": 68, "term": [37, 62, 63, 64, 69], "than": 56, "thi": [14, 15, 21], "thing": [12, 19, 53, 61], "time": [47, 52], "tl": [68, 69], "token": 43, "too": [12, 47], "train": [16, 41, 44, 47, 53, 66, 77], "transfer": [68, 69], "transform": [44, 45, 46], "tree": [75, 78], "triniti": 1, "try": 39, "type": 73, "underfit": [49, 53], "unit": [23, 36], "unstructur": 9, "unsupervis": [76, 77, 78], "us": [4, 5, 16, 20, 21, 27, 28, 29, 31, 33, 34, 35, 36, 37, 38, 41, 50, 52], "usag": 3, "v": [42, 46, 58, 69, 76], "vae": 17, "valu": [63, 65], "vanish": 50, "variat": 17, "ve": 53, "wai": 9, "want": 1, "we": [2, 7, 15, 21, 53, 66, 68], "well": 0, "what": [0, 2, 6, 7, 10, 11, 12, 13, 17, 18, 20, 21, 22, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 47, 48, 49, 50, 51, 52, 53, 54, 55, 60, 63, 64, 66, 71, 74], "when": [12, 20, 27, 28, 29, 31, 33, 34, 35, 36, 37, 38, 48, 50, 51, 68], "where": 62, "why": [0, 2, 4, 7, 10, 12, 14, 19, 20, 21, 22, 39, 46, 51, 65, 66, 70, 72], "without": 41, "word": 56, "work": [12, 18, 23, 24, 25, 26, 31, 45, 70, 72, 75], "worri": 51, "yield": 10, "you": [17, 45, 57, 60]}})