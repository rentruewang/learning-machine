{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Reinforcement Learning"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "```{note}\n",
    "We will use RL to refer to reinforcement learning.\n",
    "```"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## What is RL?\n",
    "\n",
    "RL is a branch of machine learning, focusing on interacting with things. RL was mainly developed by observing animal/human behavior, so it has a lot in common with how humans make decisions. In RL, an **agent** makes an **action** that changes an **environment**, and receives **rewards** in the process. So for example, RL can be used to model how a person, _agent_, decides to have curry for dinner, _action_, which causes some carbon footprint on earth, _environment_, and feels happy about it, _reward_. In other words, RL can be used to model problems that are interactive, about things changing, and how an action will impact future behavior, and making the right decisions. Oh, and eating curry isn't that bad for the planet earth."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Reinforce?\n",
    "\n",
    "I agree that it's a bad name. RL in its early days referred to updating a model, that's initially random, and **reinforce**/enhance the actions that yield good rewards."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Markov Decision Process"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "```{note}\n",
    "Markov Decision Process is also called MDP.\n",
    "```"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "RL is designed to optimize the rewards out of an MDP. An MDP consists of several parts we previously mentioned:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### [Agent](./essential/agent)\n",
    "\n",
    "An agent is a person or a computer or an animal, anything that makes the world around it change. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### [State](./essential/state)\n",
    "\n",
    "An agent interacts with an environment. And state is used to describe that environment. If the agent modifies the environment, we say that the state of the environment is changed."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### [Action](./essential/action)\n",
    "\n",
    "An agent makes an action to change the environment, which is, an agent makes an action to transition between states."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### [Reward](./essential/reward)\n",
    "\n",
    "Reward is obtained when making actions. Rewards are used to measure how good or bad an action is."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "So basically what RL tries to solve is to have a good agent, that takes reasonable actions between states, and try to get the most rewards."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Important terms in RL."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### [Value](./value/value)\n",
    "\n",
    "Value function refers to the total of rewards an agent will get before it dies (enters a terminated state)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### [Policy](./policy/policy)\n",
    "\n",
    "A policy refers to how an agent makes a decision."
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}